{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# yes24 크롤링"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from bs4 import BeautifulSoup\r\n",
    "import requests\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import json\r\n",
    "import time\r\n",
    "import random\r\n",
    "\r\n",
    "\r\n",
    "from fake_useragent import UserAgent"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def AladinBookListCrawler(CategoryNum, year_start, year_end, month, page):\r\n",
    "\r\n",
    "    url_1 = 'https://www.aladin.co.kr/shop/common/wbest.aspx?BestType=MonthlyBest&BranchType=1&CID='\r\n",
    "    url_2 = '&Year='\r\n",
    "    url_3 = '&Month='\r\n",
    "    url_4 = '&Week=3&page=' # 월간 판매량은 week3 기준\r\n",
    "    url_5 = '&cnt=1000&SortOrder=1'\r\n",
    "\r\n",
    "    book_list = []\r\n",
    "\r\n",
    "    for i in range(year_start, year_end+1) :\r\n",
    "        \r\n",
    "        rank=0\r\n",
    "        \r\n",
    "        print(\"Crawling 시작!\")\r\n",
    "        print(f\"====================>> {i}년\")\r\n",
    "        \r\n",
    "        for j in range(1,page+1):\r\n",
    "            \r\n",
    "            print(f\"====={j}페이지=====\")\r\n",
    "            \r\n",
    "            ua = UserAgent()\r\n",
    "            url_set = url_1 + str(CategoryNum) + url_2 + str(i) + url_3 + str(month) + url_4 + str(j) + url_5\r\n",
    "            headers = {'User-Agent' : ua.random}\r\n",
    "            res = requests.get(url_set, headers=headers)\r\n",
    "            res.raise_for_status()\r\n",
    "            soup = BeautifulSoup(res.text, \"lxml\")\r\n",
    "            \r\n",
    "            books = soup.find_all('a', class_='bo3')\r\n",
    "            \r\n",
    "            for book in books:\r\n",
    "                time.sleep(random.uniform(5,8) )\r\n",
    "                \r\n",
    "                rank += 1 # 책 순위\r\n",
    "                \r\n",
    "                book_url = book[\"href\"]\r\n",
    "                sub_res = requests.get(book_url)\r\n",
    "                sub_res.raise_for_status()\r\n",
    "                soup = BeautifulSoup(sub_res.text, \"lxml\")\r\n",
    "                \r\n",
    "                try :\r\n",
    "                    book_info = soup.find(\"script\")\r\n",
    "                    json_objects = json.loads(book_info.contents[0])\r\n",
    "                    \r\n",
    "                    book_name = json_objects['name']\r\n",
    "                    \r\n",
    "                    print(f\"====={rank}위, {book_name}=====\")\r\n",
    "                    \r\n",
    "                    author = json_objects['author']['name']\r\n",
    "                    author = author.replace(\",\", \" /\")\r\n",
    "                    pub_by = json_objects['publisher']['name']\r\n",
    "                    pub_day = json_objects['workExample'][0]['datePublished']\r\n",
    "                    price = int(json_objects['workExample'][0]['potentialAction']['expectsAcceptanceOf']['Price'])\r\n",
    "                    genre1 = soup.select_one('#ulCategory > li:nth-child(1) > a:nth-child(2)').get_text()\r\n",
    "                    genre2 = soup.select_one('#ulCategory > li:nth-child(1) > a:nth-child(3)').get_text()\r\n",
    "                    genre3 = soup.select_one('#ulCategory > li:nth-child(1) > a:nth-child(4)').get_text()\r\n",
    "                    if genre3 == \"접기\" :\r\n",
    "                        genre3 = \"\"\r\n",
    "                    book_list.append([i, month, rank, book_name, author, pub_by, pub_day, price, genre1, genre2, genre3, book_url])\r\n",
    "                except :\r\n",
    "                    print(\"오류로 스킵합니다\")\r\n",
    "                    continue\r\n",
    "    \r\n",
    "    column_list = ['year', 'month','rank', 'book_name' ,'author', 'pub_by', 'pub_day', 'price', 'genre1', 'genre2', \"genre3\", \"book_url\"]\r\n",
    "    \r\n",
    "    df = pd.DataFrame(np.array(book_list), columns=column_list)\r\n",
    "    \r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CategoryNum = 0\r\n",
    "year_start = 2001\r\n",
    "year_end = 2021\r\n",
    "month = 7\r\n",
    "page = 2\r\n",
    "\r\n",
    "\r\n",
    "AladinBookListCrawler(CategoryNum, year_start, year_end, month, page)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CategoryNum = [798, 170, 987,  336] # 건강/취미/레저X, 경제경영, 과학, 사회과학, 에세이, 인문학, 자기계발\r\n",
    "year_start = 2001\r\n",
    "year_end = 2021\r\n",
    "month = 7\r\n",
    "page = 1\r\n",
    "\r\n",
    "for i in CategoryNum:\r\n",
    "    df = AladinBookListCrawler(i, year_start, year_end, month, page)\r\n",
    "    df.to_csv(f'{year_start}_{year_end}_{i}_{month}월_순위.csv', index=False, encoding='utf-8-sig')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('tf2': conda)"
  },
  "interpreter": {
   "hash": "2c369c7a0bd18095d69cc6bcfdfaf93c8e305f9651a20b05d28ea042855c27d0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}